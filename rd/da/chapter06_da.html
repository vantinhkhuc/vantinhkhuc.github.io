<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>More Tools and Techniques for Evaluating Regression Models</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/reveal.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/theme/black.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/monokai.min.css">
    <style>
        .reveal {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        .reveal h1, .reveal h2, .reveal h3 {
            text-transform: none;
            font-weight: bold;
        }
        .reveal h1 {
            font-size: 2.5em;
            color: #42b983;
        }
        .reveal h2 {
            font-size: 1.8em;
            color: #42b983;
        }
        .reveal h3 {
            font-size: 1.4em;
            color: #64b5f6;
        }
        .reveal section {
            text-align: left;
        }
        .reveal .center {
            text-align: center;
        }
        .formula {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            font-size: 1.3em;
            text-align: center;
            border-left: 4px solid #42b983;
        }
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.8em;
        }
        .comparison-table th {
            background: #42b983;
            padding: 12px;
            text-align: left;
        }
        .comparison-table td {
            padding: 10px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }
        .comparison-table tr:hover {
            background: rgba(66, 185, 131, 0.1);
        }
        .highlight-box {
            background: rgba(66, 185, 131, 0.2);
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #42b983;
        }
        .two-columns {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            align-items: start;
        }
        .advantage {
            color: #4caf50;
        }
        .disadvantage {
            color: #f44336;
        }
        .code-container {
            margin: 15px 0;
        }
        pre code {
            max-height: 500px;
            border-radius: 8px;
        }
        .step-box {
            background: rgba(100, 181, 246, 0.2);
            padding: 15px;
            margin: 10px 0;
            border-radius: 8px;
            border-left: 4px solid #64b5f6;
        }
        .emoji {
            font-size: 1.5em;
        }
        .small-text {
            font-size: 0.8em;
            color: #aaa;
        }
        ul, ol {
            margin-left: 30px;
        }
        li {
            margin: 10px 0;
        }
        .metric-card {
            background: rgba(255, 255, 255, 0.05);
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            border: 2px solid rgba(66, 185, 131, 0.3);
        }
        .key-point {
            font-size: 1.2em;
            color: #ffd700;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="reveal">
        <div class="slides">
            
            <!-- Slide: RFE Comparison -->
            <section>
                <h2>üìà So s√°nh: T·∫•t c·∫£ bi·∫øn vs RFE</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# M√¥ h√¨nh 1: T·∫•t c·∫£ ƒë·∫∑c tr∆∞ng
model_all = LinearRegression()
model_all.fit(X_train, y_train)
y_pred_all = model_all.predict(X_test)

# M√¥ h√¨nh 2: Ch·ªâ d√πng RFE features
X_train_rfe = X_train[selected_features]
X_test_rfe = X_test[selected_features]
model_rfe = LinearRegression()
model_rfe.fit(X_train_rfe, y_train)
y_pred_rfe = model_rfe.predict(X_test_rfe)

# So s√°nh
print("T·∫•t c·∫£ bi·∫øn (8 features):")
print(f"  MAE: {mean_absolute_error(y_test, y_pred_all):.3f}")
print(f"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_all)):.3f}")
print(f"  R¬≤: {r2_score(y_test, y_pred_all):.3f}")

print("\nRFE (4 features):")
print(f"  MAE: {mean_absolute_error(y_test, y_pred_rfe):.3f}")
print(f"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rfe)):.3f}")
print(f"  R¬≤: {r2_score(y_test, y_pred_rfe):.3f}")</code></pre>
                </div>
            </section>

            <!-- Slide: RFECV -->
            <section>
                <h2>üîç RFECV - T·ª± ƒë·ªông t√¨m s·ªë l∆∞·ª£ng t·ªëi ∆∞u</h2>
                <h3>RFE with Cross-Validation</h3>

                <div class="highlight-box">
                    <p><strong>V·∫•n ƒë·ªÅ:</strong> L√†m sao bi·∫øt n√™n ch·ªçn bao nhi√™u ƒë·∫∑c tr∆∞ng?</p>
                    <p class="key-point">‚Üí RFECV t·ª± ƒë·ªông th·ª≠ nhi·ªÅu s·ªë l∆∞·ª£ng v√† ch·ªçn t·ªët nh·∫•t!</p>
                </div>

                <div class="code-container" style="margin-top: 30px;">
                    <pre><code class="python">from sklearn.feature_selection import RFECV

# RFECV v·ªõi 5-fold cross-validation
rfecv = RFECV(
    estimator=LinearRegression(),
    cv=5,
    scoring='neg_mean_squared_error',
    min_features_to_select=1
)
rfecv.fit(X, y)

print(f"S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng t·ªëi ∆∞u: {rfecv.n_features_}")
print(f"ƒê·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: {X.columns[rfecv.support_].tolist()}")

# V·∫Ω bi·ªÉu ƒë·ªì
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1),
         -rfecv.cv_results_['mean_test_score'])
plt.xlabel('S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng')
plt.ylabel('Cross-validation MSE')
plt.title('RFECV: T√¨m s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng t·ªëi ∆∞u')
plt.grid(True)
plt.show()</code></pre>
                </div>
            </section>

            <!-- PH·∫¶N 3: Tree-based Models -->
            <section class="center" data-background-gradient="linear-gradient(45deg, #2c3e50, #3498db)">
                <h1>PH·∫¶N 3</h1>
                <h2>üå≤ M√¥ h√¨nh d·ª±a tr√™n C√¢y</h2>
                <h3>Decision Tree, Random Forest, Gradient Boosting</h3>
            </section>

            <!-- Slide: Decision Tree Intro -->
            <section>
                <h2>üå≥ Decision Tree Regression</h2>
                <h3>C√¢y quy·∫øt ƒë·ªãnh cho h·ªìi quy</h3>

                <div class="two-columns">
                    <div>
                        <h3>Nguy√™n l√Ω ho·∫°t ƒë·ªông</h3>
                        <ul>
                            <li>Ph√¢n chia kh√¥ng gian d·ªØ li·ªáu th√†nh c√°c v√πng</li>
                            <li>M·ªói l√° d·ª± ƒëo√°n = gi√° tr·ªã trung b√¨nh trong v√πng</li>
                            <li>Ti√™u ch√≠ ph√¢n chia: Gi·∫£m ph∆∞∆°ng sai</li>
                        </ul>

                        <div class="step-box" style="margin-top: 30px;">
                            <p><strong>V√≠ d·ª•:</strong> D·ª± ƒëo√°n gi√° nh√†</p>
                            <p class="small-text">
                                N·∫øu di·ªán t√≠ch > 100m¬≤ ‚Üí Chi nh√°nh tr√°i<br>
                                N·∫øu s·ªë ph√≤ng > 3 ‚Üí Chi nh√°nh ph·∫£i<br>
                                ...
                            </p>
                        </div>
                    </div>
                    <div>
                        <h3 class="advantage">‚úÖ ∆Øu ƒëi·ªÉm</h3>
                        <ul>
                            <li>D·ªÖ hi·ªÉu v√† gi·∫£i th√≠ch</li>
                            <li>Kh√¥ng c·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu</li>
                            <li>X·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ s·ªë v√† categorical</li>
                            <li>T·ª± ƒë·ªông feature interaction</li>
                        </ul>

                        <h3 class="disadvantage">‚ùå Nh∆∞·ª£c ƒëi·ªÉm</h3>
                        <ul>
                            <li>D·ªÖ overfitting</li>
                            <li>Kh√¥ng ·ªïn ƒë·ªãnh (nh·∫°y v·ªõi data)</li>
                            <li>D·ª± ƒëo√°n c√≥ th·ªÉ kh√¥ng m∆∞·ª£t</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Slide: Decision Tree Code -->
            <section>
                <h2>üíª Decision Tree - Code</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
import numpy as np

# Load data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Hu·∫•n luy·ªán Decision Tree
dt_model = DecisionTreeRegressor(
    max_depth=5,              # ƒê·ªô s√¢u t·ªëi ƒëa
    min_samples_split=20,     # T·ªëi thi·ªÉu ƒë·ªÉ split
    min_samples_leaf=10,      # T·ªëi thi·ªÉu t·∫°i m·ªói l√°
    random_state=42
)
dt_model.fit(X_train, y_train)

# D·ª± ƒëo√°n
y_pred = dt_model.predict(X_test)

# ƒê√°nh gi√°
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.3f}")
print(f"RMSE: {rmse:.3f}")
print(f"R¬≤: {r2:.3f}")</code></pre>
                </div>
            </section>

            <!-- Slide: DT Hyperparameters -->
            <section>
                <h2>‚öôÔ∏è Decision Tree - Hyperparameters quan tr·ªçng</h2>
                
                <div class="metric-card">
                    <h3>max_depth</h3>
                    <p>ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y</p>
                    <p class="small-text">Nh·ªè ‚Üí Underfit | L·ªõn ‚Üí Overfit | None ‚Üí Kh√¥ng gi·ªõi h·∫°n</p>
                </div>

                <div class="metric-card">
                    <h3>min_samples_split</h3>
                    <p>S·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ ƒë∆∞·ª£c ph√©p ph√¢n chia node</p>
                    <p class="small-text">L·ªõn ‚Üí √çt ph√¢n chia ‚Üí ƒê∆°n gi·∫£n h∆°n | Nh·ªè ‚Üí Ph·ª©c t·∫°p h∆°n</p>
                </div>

                <div class="metric-card">
                    <h3>min_samples_leaf</h3>
                    <p>S·ªë m·∫´u t·ªëi thi·ªÉu ·ªü m·ªói node l√°</p>
                    <p class="small-text">L·ªõn ‚Üí M∆∞·ª£t m√† h∆°n | Nh·ªè ‚Üí Chi ti·∫øt h∆°n</p>
                </div>

                <div class="highlight-box" style="margin-top: 30px;">
                    <p class="key-point">üéØ Chi·∫øn l∆∞·ª£c: B·∫Øt ƒë·∫ßu v·ªõi max_depth nh·ªè (3-5) r·ªìi tƒÉng d·∫ßn!</p>
                </div>
            </section>

            <!-- Slide: Random Forest Intro -->
            <section>
                <h2>üå≤üå≤üå≤ Random Forest Regression</h2>
                <h3>R·ª´ng c√¢y quy·∫øt ƒë·ªãnh</h3>

                <div class="highlight-box">
                    <p class="key-point">√ù t∆∞·ªüng: "S·ª©c m·∫°nh c·ªßa t·∫≠p th·ªÉ!"</p>
                    <p>Ensemble c·ªßa nhi·ªÅu Decision Trees ‚Üí K·∫øt qu·∫£ trung b√¨nh</p>
                </div>

                <div class="two-columns" style="margin-top: 30px;">
                    <div>
                        <h3>C∆° ch·∫ø ho·∫°t ƒë·ªông</h3>
                        <div class="step-box">
                            <p><strong>1. Bootstrap Sampling</strong></p>
                            <p class="small-text">T·∫°o nhi·ªÅu t·∫≠p train kh√°c nhau (c√≥ ho√†n l·∫°i)</p>
                        </div>
                        <div class="step-box">
                            <p><strong>2. Random Features</strong></p>
                            <p class="small-text">M·ªói split ch·ªâ x√©t subset ng·∫´u nhi√™n c√°c bi·∫øn</p>
                        </div>
                        <div class="step-box">
                            <p><strong>3. Training</strong></p>
                            <p class="small-text">Hu·∫•n luy·ªán nhi·ªÅu c√¢y ƒë·ªôc l·∫≠p</p>
                        </div>
                        <div class="step-box">
                            <p><strong>4. Prediction</strong></p>
                            <p class="small-text">Trung b√¨nh k·∫øt qu·∫£ c·ªßa t·∫•t c·∫£ c√¢y</p>
                        </div>
                    </div>
                    <div>
                        <h3 class="advantage">‚úÖ ∆Øu ƒëi·ªÉm</h3>
                        <ul>
                            <li>R·∫•t ch√≠nh x√°c</li>
                            <li>Gi·∫£m overfitting so v·ªõi DT</li>
                            <li>·ªîn ƒë·ªãnh, robust</li>
                            <li>Feature importance t·ª± ƒë·ªông</li>
                            <li>X·ª≠ l√Ω t·ªët d·ªØ li·ªáu nhi·ªÖu</li>
                        </ul>

                        <h3 class="disadvantage">‚ùå Nh∆∞·ª£c ƒëi·ªÉm</h3>
                        <ul>
                            <li>Ch·∫≠m h∆°n DT (nhi·ªÅu c√¢y)</li>
                            <li>Kh√≥ gi·∫£i th√≠ch</li>
                            <li>T·ªën b·ªô nh·ªõ</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Slide: Random Forest Code -->
            <section>
                <h2>üíª Random Forest - Code</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.ensemble import RandomForestRegressor
import pandas as pd

# Hu·∫•n luy·ªán Random Forest
rf_model = RandomForestRegressor(
    n_estimators=100,      # S·ªë l∆∞·ª£ng c√¢y
    max_depth=10,          # ƒê·ªô s√¢u m·ªói c√¢y
    min_samples_split=5,   # T·ªëi thi·ªÉu ƒë·ªÉ split
    max_features='sqrt',   # S·ªë bi·∫øn x√©t ·ªü m·ªói split
    random_state=42,
    n_jobs=-1              # D√πng t·∫•t c·∫£ CPU cores
)
rf_model.fit(X_train, y_train)

# D·ª± ƒëo√°n v√† ƒë√°nh gi√°
y_pred = rf_model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.3f} | RMSE: {rmse:.3f} | R¬≤: {r2:.3f}")

# Feature Importance
importances = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nTop 5 Features:")
print(importances.head())</code></pre>
                </div>
            </section>

            <!-- Slide: RF Feature Importance -->
            <section>
                <h2>üìä Random Forest - Feature Importance</h2>
                
                <div class="highlight-box">
                    <p><strong>Feature Importance:</strong> ƒêo l∆∞·ªùng ƒë√≥ng g√≥p c·ªßa m·ªói bi·∫øn v√†o d·ª± ƒëo√°n</p>
                    <p class="small-text">C√†ng cao ‚Üí C√†ng quan tr·ªçng</p>
                </div>

                <div class="code-container">
                    <pre><code class="python">import matplotlib.pyplot as plt

# V·∫Ω bi·ªÉu ƒë·ªì Feature Importance
plt.figure(figsize=(10, 6))
importances_sorted = importances.head(10)
plt.barh(importances_sorted['Feature'], importances_sorted['Importance'])
plt.xlabel('Importance')
plt.title('Top 10 Feature Importance - Random Forest')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# So s√°nh v·ªõi RFE
print("\nSo s√°nh:")
print("RFE ch·ªçn:", selected_features.tolist())
print("RF Top 4:", importances.head(4)['Feature'].tolist())</code></pre>
                </div>

                <div class="step-box" style="margin-top: 30px;">
                    <p><span class="emoji">üí°</span> <strong>Insight:</strong> Feature Importance t·ª´ RF c√≥ th·ªÉ kh√°c v·ªõi RFE!</p>
                    <p class="small-text">RF xem x√©t non-linear relationships, RFE d·ª±a tr√™n linear model</p>
                </div>
            </section>

            <!-- Slide: Gradient Boosting Intro -->
            <section>
                <h2>üöÄ Gradient Boosting Regression</h2>
                <h3>TƒÉng c∆∞·ªùng Gradient</h3>

                <div class="highlight-box">
                    <p class="key-point">√ù t∆∞·ªüng: "H·ªçc t·ª´ sai l·∫ßm!"</p>
                    <p>X√¢y d·ª±ng c√¢y tu·∫ßn t·ª±, m·ªói c√¢y s·ª≠a l·ªói c·ªßa c√¢y tr∆∞·ªõc</p>
                </div>

                <div class="two-columns" style="margin-top: 30px;">
                    <div>
                        <h3>C∆° ch·∫ø ho·∫°t ƒë·ªông</h3>
                        <div class="step-box">
                            <p><strong>1. C√¢y ƒë·∫ßu ti√™n</strong></p>
                            <p class="small-text">D·ª± ƒëo√°n gi√° tr·ªã trung b√¨nh ƒë∆°n gi·∫£n</p>
                        </div>
                        <div class="step-box">
                            <p><strong>2. T√≠nh residuals</strong></p>
                            <p class="small-text">Sai s·ªë = y_true - y_pred</p>
                        </div>
                        <div class="step-box">
                            <p><strong>3. C√¢y ti·∫øp theo</strong></p>
                            <p class="small-text">H·ªçc d·ª± ƒëo√°n residuals</p>
                        </div>
                        <div class="step-box">
                            <p><strong>4. L·∫∑p l·∫°i</strong></p>
                            <p class="small-text">n_estimators l·∫ßn</p>
                        </div>
                        <div class="step-box">
                            <p><strong>5. K·∫øt qu·∫£ cu·ªëi</strong></p>
                            <p class="small-text">T·ªïng t·∫•t c·∫£ c√¢y √ó learning_rate</p>
                        </div>
                    </div>
                    <div>
                        <h3 class="advantage">‚úÖ ∆Øu ƒëi·ªÉm</h3>
                        <ul>
                            <li><strong>R·∫•t ch√≠nh x√°c</strong> - Th∆∞·ªùng t·ªët nh·∫•t</li>
                            <li>Linh ho·∫°t v·ªõi nhi·ªÅu loss functions</li>
                            <li>Feature importance t·ªët</li>
                            <li>X·ª≠ l√Ω ƒë∆∞·ª£c missing values</li>
                        </ul>

                        <h3 class="disadvantage">‚ùå Nh∆∞·ª£c ƒëi·ªÉm</h3>
                        <ul>
                            <li>D·ªÖ overfit n·∫øu kh√¥ng tune k·ªπ</li>
                            <li>Ch·∫≠m (training tu·∫ßn t·ª±)</li>
                            <li>Nhi·ªÅu hyperparameters</li>
                            <li>Kh√≥ gi·∫£i th√≠ch</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Slide: Gradient Boosting Code -->
            <section>
                <h2>üíª Gradient Boosting - Code</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.ensemble import GradientBoostingRegressor

# Hu·∫•n luy·ªán Gradient Boosting
gb_model = GradientBoostingRegressor(
    n_estimators=100,      # S·ªë l∆∞·ª£ng c√¢y
    learning_rate=0.1,     # T·ªëc ƒë·ªô h·ªçc (quan tr·ªçng!)
    max_depth=3,           # ƒê·ªô s√¢u m·ªói c√¢y (th∆∞·ªùng nh·ªè 3-5)
    min_samples_split=20,
    min_samples_leaf=10,
    subsample=0.8,         # T·ª∑ l·ªá sample cho m·ªói c√¢y
    random_state=42
)
gb_model.fit(X_train, y_train)

# D·ª± ƒëo√°n v√† ƒë√°nh gi√°
y_pred = gb_model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.3f}")
print(f"RMSE: {rmse:.3f}")
print(f"R¬≤: {r2:.3f}")</code></pre>
                </div>

                <div class="highlight-box" style="margin-top: 20px;">
                    <p><span class="emoji">‚ö†Ô∏è</span> <strong>L∆∞u √Ω:</strong> learning_rate nh·ªè (0.01-0.1) + nhi·ªÅu c√¢y = T·ªët h∆°n nh∆∞ng ch·∫≠m h∆°n</p>
                </div>
            </section>

            <!-- Slide: GB Hyperparameters -->
            <section>
                <h2>‚öôÔ∏è Gradient Boosting - Key Hyperparameters</h2>
                
                <div class="metric-card">
                    <h3>learning_rate (Œ∑)</h3>
                    <p><strong>T·ªëc ƒë·ªô h·ªçc:</strong> Shrinkage factor cho m·ªói c√¢y</p>
                    <ul class="small-text">
                        <li>Nh·ªè (0.01-0.05): Ch√≠nh x√°c h∆°n, c·∫ßn nhi·ªÅu c√¢y, ch·∫≠m</li>
                        <li>Trung b√¨nh (0.1): C√¢n b·∫±ng t·ªët</li>
                        <li>L·ªõn (0.3+): Nhanh nh∆∞ng d·ªÖ overfit</li>
                    </ul>
                </div>

                <div class="metric-card">
                    <h3>n_estimators</h3>
                    <p><strong>S·ªë l∆∞·ª£ng c√¢y:</strong> Nhi·ªÅu c√¢y ‚Üí T·ªët h∆°n (ƒë·∫øn m·ªôt ƒëi·ªÉm)</p>
                    <p class="small-text">Tip: learning_rate nh·ªè ‚Üí c·∫ßn n_estimators l·ªõn</p>
                </div>

                <div class="metric-card">
                    <h3>max_depth</h3>
                    <p><strong>ƒê·ªô s√¢u:</strong> Th∆∞·ªùng nh·ªè (3-5) cho GB</p>
                    <p class="small-text">GB d√πng "weak learners" - c√¢y n√¥ng t·ªët h∆°n</p>
                </div>

                <div class="highlight-box" style="margin-top: 20px;">
                    <p class="key-point">üéØ C√¥ng th·ª©c v√†ng: learning_rate ‚Üì th√¨ n_estimators ‚Üë</p>
                </div>
            </section>

            <!-- Slide: Compare Tree Models -->
            <section>
                <h2>‚öñÔ∏è So s√°nh c√°c m√¥ h√¨nh Tree-based</h2>
                
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Ti√™u ch√≠</th>
                            <th>Decision Tree</th>
                            <th>Random Forest</th>
                            <th>Gradient Boosting</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>ƒê·ªô ch√≠nh x√°c</strong></td>
                            <td>‚≠ê‚≠ê</td>
                            <td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
                            <td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
                        </tr>
                        <tr>
                            <td><strong>T·ªëc ƒë·ªô training</strong></td>
                            <td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
                            <td>‚≠ê‚≠ê‚≠ê</td>
                            <td>‚≠ê‚≠ê</td>
                        </tr>
                        <tr>
                            <td><strong>Kh·∫£ nƒÉng gi·∫£i th√≠ch</strong></td>
                            <td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
                            <td>‚≠ê‚≠ê</td>
                            <td>‚≠ê‚≠ê</td>
                        </tr>
                        <tr>
                            <td><strong>Ch·ªëng overfit</strong></td>
                            <td>‚≠ê</td>
                            <td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
                            <td>‚≠ê‚≠ê‚≠ê</td>
                        </tr>
                        <tr>
                            <td><strong>Khi n√†o d√πng</strong></td>
                            <td>Baseline, c·∫ßn gi·∫£i th√≠ch</td>
                            <td>D·ªØ li·ªáu ph·ª©c t·∫°p, robust</td>
                            <td>C·∫ßn ƒë·ªô ch√≠nh x√°c cao nh·∫•t</td>
                        </tr>
                        <tr>
                            <td><strong>Training</strong></td>
                            <td>Single tree</td>
                            <td>Parallel (nhi·ªÅu c√¢y)</td>
                            <td>Sequential (tu·∫ßn t·ª±)</td>
                        </tr>
                    </tbody>
                </table>

                <div class="highlight-box" style="margin-top: 30px;">
                    <p class="key-point">üí° Khuy·∫øn ngh·ªã: Th·ª≠ c·∫£ 3! M·ªói model c√≥ ƒëi·ªÉm m·∫°nh ri√™ng</p>
                </div>
            </section>

            <!-- PH·∫¶N 4: Model Comparison -->
            <section class="center" data-background-gradient="linear-gradient(45deg, #614385, #516395)">
                <h1>PH·∫¶N 4</h1>
                <h2>üèÜ So s√°nh v√† L·ª±a ch·ªçn M√¥ h√¨nh</h2>
                <h3>Framework ƒë√°nh gi√° to√†n di·ªán</h3>
            </section>

            <!-- Slide: Evaluation Framework -->
            <section>
                <h2>üéØ Framework ƒë√°nh gi√° M√¥ h√¨nh</h2>
                
                <div class="step-box">
                    <h3>B∆∞·ªõc 1: Chia d·ªØ li·ªáu</h3>
                    <p>Train/Test split ho·∫∑c Cross-Validation (t·ªët h∆°n!)</p>
                </div>

                <div class="step-box">
                    <h3>B∆∞·ªõc 2: Hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh</h3>
                    <p>Linear, Tree-based, Ensemble...</p>
                </div>

                <div class="step-box">
                    <h3>B∆∞·ªõc 3: ƒê√°nh gi√° v·ªõi nhi·ªÅu metrics</h3>
                    <p>MAE, RMSE, R¬≤, Training time, Prediction time</p>
                </div>

                <div class="step-box">
                    <h3>B∆∞·ªõc 4: So s√°nh k·∫øt qu·∫£</h3>
                    <p>T·∫°o b·∫£ng so s√°nh, visualization</p>
                </div>

                <div class="step-box">
                    <h3>B∆∞·ªõc 5: L·ª±a ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t</h3>
                    <p>C√¢n nh·∫Øc: Accuracy, Speed, Interpretability, Business needs</p>
                </div>
            </section>

            <!-- Slide: Comprehensive Comparison Code -->
            <section>
                <h2>üíª So s√°nh to√†n di·ªán - Code (1/2)</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import pandas as pd
import time

# Danh s√°ch m√¥ h√¨nh
models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0),
    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),
    'Random Forest': RandomForestRegressor(n_estimators=100, 
                                           max_depth=10, 
                                           random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100,
                                                    learning_rate=0.1,
                                                    max_depth=3,
                                                    random_state=42)
}

results = []</code></pre>
                </div>
            </section>

            <!-- Slide: Comprehensive Comparison Code 2 -->
            <section>
                <h2>üíª So s√°nh to√†n di·ªán - Code (2/2)</h2>
                <div class="code-container">
                    <pre><code class="python">for name, model in models.items():
    print(f"Training {name}...")
    
    # Training time
    start_time = time.time()
    model.fit(X_train, y_train)
    train_time = time.time() - start_time
    
    # Prediction time
    start_time = time.time()
    y_pred = model.predict(X_test)
    pred_time = time.time() - start_time
    
    # Metrics
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    
    # Cross-validation R¬≤
    cv_scores = cross_val_score(model, X, y, cv=5, 
                                 scoring='r2')
    
    results.append({
        'Model': name,
        'MAE': mae,
        'RMSE': rmse,
        'R¬≤': r2,
        'CV R¬≤ Mean': cv_scores.mean(),
        'CV R¬≤ Std': cv_scores.std(),
        'Train Time (s)': train_time,
        'Pred Time (s)': pred_time
    })

# T·∫°o DataFrame
comparison_df = pd.DataFrame(results)
comparison_df = comparison_df.sort_values('RMSE')
print(comparison_df)</code></pre>
                </div>
            </section>

            <!-- Slide: Example Results -->
            <section>
                <h2>üìä K·∫øt qu·∫£ so s√°nh (V√≠ d·ª•)</h2>
                
                <table class="comparison-table" style="font-size: 0.7em;">
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>MAE</th>
                            <th>RMSE</th>
                            <th>R¬≤</th>
                            <th>CV R¬≤</th>
                            <th>Train(s)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr style="background: rgba(255 Slide 1: Title -->
            <section class="center">
                <h1>üìä More Tools and Techniques for Evaluating Regression Models</h1>
                <h3>Ph√¢n t√≠ch d·ªØ li·ªáu trong Kinh doanh</h3>
                <p style="margin-top: 50px;">
                    <strong>Th·ªùi l∆∞·ª£ng:</strong> 150 ph√∫t<br>
                    <strong>Ng√¥n ng·ªØ:</strong> Python + Scikit-learn
                </p>
                <p class="small-text" style="margin-top: 50px;">
                    Nh·∫•n ph√≠m m≈©i t√™n ho·∫∑c Space ƒë·ªÉ chuy·ªÉn slide<br>
                    Nh·∫•n 'F' ƒë·ªÉ to√†n m√†n h√¨nh | 'Esc' ƒë·ªÉ xem t·ªïng quan
                </p>
            </section>

            <!-- Slide 2: Learning Objectives -->
            <section>
                <h2>üéØ M·ª•c ti√™u bu·ªïi h·ªçc</h2>
                <div class="highlight-box">
                    <p>Sau bu·ªïi h·ªçc n√†y, sinh vi√™n c√≥ th·ªÉ:</p>
                    <ul>
                        <li><strong>Hi·ªÉu v√† √°p d·ª•ng</strong> c√°c th∆∞·ªõc ƒëo ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh h·ªìi quy</li>
                        <li><strong>T√≠nh to√°n v√† gi·∫£i th√≠ch</strong> MAE v√† RMSE</li>
                        <li><strong>S·ª≠ d·ª•ng</strong> Recursive Feature Elimination (RFE) ƒë·ªÉ l·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng</li>
                        <li><strong>So s√°nh v√† ƒë√°nh gi√°</strong> c√°c m√¥ h√¨nh h·ªìi quy d·ª±a tr√™n c√¢y quy·∫øt ƒë·ªãnh</li>
                        <li><strong>L·ª±a ch·ªçn m√¥ h√¨nh</strong> ph√π h·ª£p nh·∫•t cho b√†i to√°n c·ª• th·ªÉ</li>
                    </ul>
                </div>
            </section>

            <!-- Slide 3: Agenda -->
            <section>
                <h2>üìã N·ªôi dung bu·ªïi h·ªçc</h2>
                <div class="two-columns">
                    <div>
                        <h3>Ph·∫ßn 1 (40')</h3>
                        <ul>
                            <li>Gi·ªõi thi·ªáu</li>
                            <li>MAE - Mean Absolute Error</li>
                            <li>RMSE - Root Mean Squared Error</li>
                            <li>So s√°nh MAE vs RMSE</li>
                        </ul>
                        
                        <h3>Ph·∫ßn 2 (45')</h3>
                        <ul>
                            <li>Feature Selection</li>
                            <li>Recursive Feature Elimination</li>
                            <li>RFECV</li>
                        </ul>
                    </div>
                    <div>
                        <h3>Ph·∫ßn 3 (40')</h3>
                        <ul>
                            <li>Decision Tree Regression</li>
                            <li>Random Forest Regression</li>
                            <li>Gradient Boosting</li>
                            <li>So s√°nh c√°c m√¥ h√¨nh</li>
                        </ul>
                        
                        <h3>Ph·∫ßn 4 (15')</h3>
                        <ul>
                            <li>Framework ƒë√°nh gi√°</li>
                            <li>L·ª±a ch·ªçn m√¥ h√¨nh</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- PH·∫¶N 1: EVALUATION METRICS -->
            <section class="center" data-background-gradient="linear-gradient(45deg, #1e3c72, #2a5298)">
                <h1>PH·∫¶N 1</h1>
                <h2>üìè C√°c th∆∞·ªõc ƒëo ƒë√°nh gi√°</h2>
                <h3>MAE & RMSE</h3>
            </section>

            <!-- Slide: Why More Metrics -->
            <section>
                <h2>‚ùì T·∫°i sao c·∫ßn nhi·ªÅu th∆∞·ªõc ƒëo?</h2>
                <div class="highlight-box">
                    <p class="key-point">R¬≤ v√† RSS kh√¥ng ƒë·ªß!</p>
                </div>
                <ul>
                    <li><strong>R¬≤</strong>: Ch·ªâ cho bi·∫øt t·ª∑ l·ªá ph∆∞∆°ng sai ƒë∆∞·ª£c gi·∫£i th√≠ch
                        <ul>
                            <li>Kh√¥ng cho bi·∫øt ƒë·ªô l·ªõn sai s·ªë th·ª±c t·∫ø</li>
                            <li>Kh√≥ so s√°nh gi·ªØa c√°c dataset kh√°c nhau</li>
                        </ul>
                    </li>
                    <li><strong>RSS</strong>: Ph·ª• thu·ªôc v√†o s·ªë l∆∞·ª£ng m·∫´u
                        <ul>
                            <li>Kh√≥ di·ªÖn gi·∫£i v·ªõi ng∆∞·ªùi kh√¥ng chuy√™n</li>
                            <li>Kh√¥ng c√≥ ƒë∆°n v·ªã th·ª±c t·∫ø</li>
                        </ul>
                    </li>
                </ul>
                <div class="step-box" style="margin-top: 30px;">
                    <p><span class="emoji">üí°</span> <strong>Gi·∫£i ph√°p:</strong> S·ª≠ d·ª•ng MAE v√† RMSE - c√°c metric d·ªÖ hi·ªÉu, c√≥ ƒë∆°n v·ªã gi·ªëng bi·∫øn m·ª•c ti√™u</p>
                </div>
            </section>

            <!-- Slide: MAE Theory -->
            <section>
                <h2>üìä MAE - Mean Absolute Error</h2>
                <h3>Sai s·ªë tuy·ªát ƒë·ªëi trung b√¨nh</h3>
                
                <div class="formula">
                    MAE = (1/n) √ó Œ£|y<sub>i</sub> - ≈∑<sub>i</sub>|
                </div>

                <div class="two-columns">
                    <div>
                        <h3 class="advantage">‚úÖ ∆Øu ƒëi·ªÉm</h3>
                        <ul>
                            <li>D·ªÖ hi·ªÉu v√† di·ªÖn gi·∫£i</li>
                            <li>C√πng ƒë∆°n v·ªã v·ªõi bi·∫øn m·ª•c ti√™u</li>
                            <li>√çt b·ªã ·∫£nh h∆∞·ªüng b·ªüi outliers</li>
                            <li>Robust v·ªõi d·ªØ li·ªáu nhi·ªÖu</li>
                        </ul>
                    </div>
                    <div>
                        <h3 class="disadvantage">‚ùå Nh∆∞·ª£c ƒëi·ªÉm</h3>
                        <ul>
                            <li>Kh√¥ng ph√¢n bi·ªát m·ª©c ƒë·ªô nghi√™m tr·ªçng c·ªßa sai s·ªë</li>
                            <li>Kh√¥ng ph·∫°t n·∫∑ng c√°c sai s·ªë l·ªõn</li>
                            <li>C√≥ th·ªÉ b·ªè qua c√°c d·ª± ƒëo√°n sai nghi√™m tr·ªçng</li>
                        </ul>
                    </div>
                </div>

                <div class="highlight-box" style="margin-top: 20px;">
                    <p><strong>V√≠ d·ª•:</strong> D·ª± ƒëo√°n gi√° nh√† v·ªõi MAE = 500 tri·ªáu VNƒê<br>
                    ‚Üí Trung b√¨nh sai l·ªách 500 tri·ªáu so v·ªõi gi√° th·ª±c t·∫ø</p>
                </div>
            </section>

            <!-- Slide: MAE Code -->
            <section>
                <h2>üíª MAE - Th·ª±c h√†nh v·ªõi Python</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.metrics import mean_absolute_error
import numpy as np

# D·ªØ li·ªáu th·ª±c t·∫ø v√† d·ª± ƒëo√°n
y_true = np.array([3.5, 4.2, 2.8, 5.1, 3.9])
y_pred = np.array([3.2, 4.5, 2.9, 4.8, 4.1])

# T√≠nh MAE
mae = mean_absolute_error(y_true, y_pred)
print(f"MAE: {mae:.2f}")

# T√≠nh MAE th·ªß c√¥ng
manual_mae = np.mean(np.abs(y_true - y_pred))
print(f"MAE (manual): {manual_mae:.2f}")

# Output:
# MAE: 0.26
# MAE (manual): 0.26</code></pre>
                </div>
                
                <div class="highlight-box">
                    <p><span class="emoji">üéØ</span> <strong>B√†i t·∫≠p:</strong> T√≠nh MAE cho d·ªØ li·ªáu c·ªßa b·∫°n v√† gi·∫£i th√≠ch √Ω nghƒ©a!</p>
                </div>
            </section>

            <!-- Slide: RMSE Theory -->
            <section>
                <h2>üìà RMSE - Root Mean Squared Error</h2>
                <h3>CƒÉn b·∫≠c hai c·ªßa trung b√¨nh b√¨nh ph∆∞∆°ng sai s·ªë</h3>
                
                <div class="formula">
                    RMSE = ‚àö[(1/n) √ó Œ£(y<sub>i</sub> - ≈∑<sub>i</sub>)¬≤]
                </div>

                <div class="two-columns">
                    <div>
                        <h3 class="advantage">‚úÖ ∆Øu ƒëi·ªÉm</h3>
                        <ul>
                            <li>Ph·∫°t n·∫∑ng c√°c sai s·ªë l·ªõn</li>
                            <li>Nh·∫°y c·∫£m v·ªõi outliers</li>
                            <li>C√πng ƒë∆°n v·ªã v·ªõi bi·∫øn m·ª•c ti√™u</li>
                            <li>Th∆∞·ªùng d√πng trong t·ªëi ∆∞u h√≥a</li>
                        </ul>
                    </div>
                    <div>
                        <h3 class="disadvantage">‚ùå Nh∆∞·ª£c ƒëi·ªÉm</h3>
                        <ul>
                            <li>Kh√≥ gi·∫£i th√≠ch h∆°n MAE</li>
                            <li>R·∫•t nh·∫°y c·∫£m v·ªõi outliers</li>
                            <li>C√≥ th·ªÉ b·ªã chi ph·ªëi b·ªüi v√†i gi√° tr·ªã l·ªõn</li>
                        </ul>
                    </div>
                </div>

                <div class="step-box" style="margin-top: 20px;">
                    <p><strong>üí° Khi n√†o d√πng RMSE?</strong></p>
                    <ul>
                        <li>Khi sai s·ªë l·ªõn c·∫ßn ƒë∆∞·ª£c ph·∫°t n·∫∑ng (y t·∫ø, t√†i ch√≠nh)</li>
                        <li>Khi mu·ªën m√¥ h√¨nh tr√°nh c√°c d·ª± ƒëo√°n sai qu√° xa</li>
                        <li>Khi d·ªØ li·ªáu kh√¥ng c√≥ nhi·ªÅu outliers</li>
                    </ul>
                </div>
            </section>

            <!-- Slide: RMSE Code -->
            <section>
                <h2>üíª RMSE - Th·ª±c h√†nh v·ªõi Python</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.metrics import mean_squared_error
import numpy as np

# D·ªØ li·ªáu
y_true = np.array([3.5, 4.2, 2.8, 5.1, 3.9])
y_pred = np.array([3.2, 4.5, 2.9, 4.8, 4.1])

# T√≠nh RMSE
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
print(f"RMSE: {rmse:.2f}")

# T√≠nh RMSE th·ªß c√¥ng
manual_rmse = np.sqrt(np.mean((y_true - y_pred)**2))
print(f"RMSE (manual): {manual_rmse:.2f}")

# So s√°nh v·ªõi MAE
mae = mean_absolute_error(y_true, y_pred)
print(f"MAE: {mae:.2f}")
print(f"RMSE/MAE ratio: {rmse/mae:.2f}")

# Output:
# RMSE: 0.28
# RMSE (manual): 0.28
# MAE: 0.26
# RMSE/MAE ratio: 1.08</code></pre>
                </div>
            </section>

            <!-- Slide: MAE vs RMSE Comparison -->
            <section>
                <h2>‚öñÔ∏è So s√°nh MAE vs RMSE</h2>
                
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Ti√™u ch√≠</th>
                            <th>MAE</th>
                            <th>RMSE</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>C√¥ng th·ª©c</strong></td>
                            <td>Œ£|error| / n</td>
                            <td>‚àö(Œ£error¬≤ / n)</td>
                        </tr>
                        <tr>
                            <td><strong>ƒê·ªô nh·∫°y outliers</strong></td>
                            <td>Th·∫•p ‚≠ê</td>
                            <td>Cao ‚≠ê‚≠ê‚≠ê</td>
                        </tr>
                        <tr>
                            <td><strong>D·ªÖ gi·∫£i th√≠ch</strong></td>
                            <td>Cao ‚≠ê‚≠ê‚≠ê</td>
                            <td>Trung b√¨nh ‚≠ê‚≠ê</td>
                        </tr>
                        <tr>
                            <td><strong>Ph·∫°t sai s·ªë l·ªõn</strong></td>
                            <td>Tuy·∫øn t√≠nh</td>
                            <td>B·∫≠c 2 (n·∫∑ng h∆°n)</td>
                        </tr>
                        <tr>
                            <td><strong>Khi n√†o d√πng</strong></td>
                            <td>Nhi·ªÅu outliers, c·∫ßn di·ªÖn gi·∫£i</td>
                            <td>C·∫ßn ph·∫°t n·∫∑ng sai s·ªë l·ªõn</td>
                        </tr>
                    </tbody>
                </table>

                <div class="highlight-box" style="margin-top: 30px;">
                    <p class="key-point">‚ö° Quy t·∫Øc v√†ng: RMSE ‚â• MAE (lu√¥n ƒë√∫ng!)</p>
                    <p>Khi RMSE ‚âà MAE: Sai s·ªë ph√¢n b·ªë ƒë·ªÅu<br>
                    Khi RMSE >> MAE: C√≥ nhi·ªÅu outliers ho·∫∑c sai s·ªë l·ªõn</p>
                </div>
            </section>

            <!-- Slide: Practical Example -->
            <section>
                <h2>üè† V√≠ d·ª• th·ª±c t·∫ø: D·ª± ƒëo√°n gi√° nh√†</h2>
                
                <div class="metric-card">
                    <h3>M√¥ h√¨nh A</h3>
                    <p>MAE = 500 tri·ªáu | RMSE = 520 tri·ªáu | Ratio = 1.04</p>
                    <p class="small-text">‚Üí Sai s·ªë kh√° ƒë·ªÅu, √≠t outliers</p>
                </div>

                <div class="metric-card">
                    <h3>M√¥ h√¨nh B</h3>
                    <p>MAE = 500 tri·ªáu | RMSE = 800 tri·ªáu | Ratio = 1.60</p>
                    <p class="small-text">‚Üí C√≥ nhi·ªÅu d·ª± ƒëo√°n sai r·∫•t xa, c·∫ßn c·∫£i thi·ªán!</p>
                </div>

                <div class="step-box" style="margin-top: 30px;">
                    <p><strong>ü§î C√¢u h·ªèi:</strong> B·∫°n ch·ªçn m√¥ h√¨nh n√†o?</p>
                    <p><strong>Tr·∫£ l·ªùi:</strong> M√¥ h√¨nh A! V√¨ sai s·ªë ·ªïn ƒë·ªãnh h∆°n, ƒë√°ng tin c·∫≠y h∆°n trong th·ª±c t·∫ø</p>
                </div>
            </section>

            <!-- PH·∫¶N 2: RFE -->
            <section class="center" data-background-gradient="linear-gradient(45deg, #134e5e, #71b280)">
                <h1>PH·∫¶N 2</h1>
                <h2>üéØ Feature Selection</h2>
                <h3>Recursive Feature Elimination</h3>
            </section>

            <!-- Slide: Why Feature Selection -->
            <section>
                <h2>ü§î T·∫°i sao c·∫ßn l·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng?</h2>
                
                <div class="two-columns">
                    <div>
                        <h3>‚ö†Ô∏è V·∫•n ƒë·ªÅ</h3>
                        <ul>
                            <li><strong>Curse of Dimensionality</strong>
                                <ul><li>Qu√° nhi·ªÅu bi·∫øn ‚Üí d·ªØ li·ªáu th∆∞a</li></ul>
                            </li>
                            <li><strong>Overfitting</strong>
                                <ul><li>M√¥ h√¨nh h·ªçc noise thay v√¨ pattern</li></ul>
                            </li>
                            <li><strong>Th·ªùi gian training</strong>
                                <ul><li>C√†ng nhi·ªÅu bi·∫øn ‚Üí c√†ng ch·∫≠m</li></ul>
                            </li>
                            <li><strong>Kh√≥ gi·∫£i th√≠ch</strong>
                                <ul><li>Business kh√¥ng hi·ªÉu m√¥ h√¨nh</li></ul>
                            </li>
                        </ul>
                    </div>
                    <div>
                        <h3>‚úÖ L·ª£i √≠ch</h3>
                        <ul>
                            <li><strong>Gi·∫£m overfitting</strong>
                                <ul><li>M√¥ h√¨nh t·ªïng qu√°t h√≥a t·ªët h∆°n</li></ul>
                            </li>
                            <li><strong>TƒÉng hi·ªáu su·∫•t</strong>
                                <ul><li>Training v√† prediction nhanh h∆°n</li></ul>
                            </li>
                            <li><strong>D·ªÖ gi·∫£i th√≠ch</strong>
                                <ul><li>T·∫≠p trung v√†o bi·∫øn quan tr·ªçng</li></ul>
                            </li>
                            <li><strong>Gi·∫£m chi ph√≠</strong>
                                <ul><li>Thu th·∫≠p √≠t d·ªØ li·ªáu h∆°n</li></ul>
                            </li>
                        </ul>
                    </div>
                </div>

                <div class="highlight-box" style="margin-top: 30px;">
                    <p class="key-point">üéØ M·ª•c ti√™u: Ch·ªçn t·∫≠p con ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t!</p>
                    <p>T·ªët nh·∫•t = ƒê·ªß th√¥ng tin + √çt bi·∫øn nh·∫•t + Kh√¥ng redundant</p>
                </div>
            </section>

            <!-- Slide: Feature Selection Methods -->
            <section>
                <h2>üõ†Ô∏è C√°c ph∆∞∆°ng ph√°p l·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng</h2>
                
                <div class="step-box">
                    <h3>1. Filter Methods</h3>
                    <p>ƒê√°nh gi√° t·ª´ng bi·∫øn ƒë·ªôc l·∫≠p (correlation, chi-square, ...)</p>
                    <p class="small-text">‚úÖ Nhanh | ‚ùå Kh√¥ng xem x√©t t∆∞∆°ng t√°c gi·ªØa c√°c bi·∫øn</p>
                </div>

                <div class="step-box">
                    <h3>2. Wrapper Methods</h3>
                    <p>S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ ƒë√°nh gi√° t·∫≠p con (RFE, Forward/Backward Selection)</p>
                    <p class="small-text">‚úÖ Xem x√©t t∆∞∆°ng t√°c | ‚ùå Ch·∫≠m, t·ªën t√†i nguy√™n</p>
                </div>

                <div class="step-box">
                    <h3>3. Embedded Methods</h3>
                    <p>L·ª±a ch·ªçn trong qu√° tr√¨nh training (Lasso, Tree-based importance)</p>
                    <p class="small-text">‚úÖ C√¢n b·∫±ng t·ªëc ƒë·ªô v√† hi·ªáu qu·∫£ | ‚ùå Ph·ª• thu·ªôc m√¥ h√¨nh</p>
                </div>

                <div class="highlight-box" style="margin-top: 20px;">
                    <p><strong>H√¥m nay t·∫≠p trung:</strong> <span class="key-point">RFE (Wrapper Method)</span></p>
                </div>
            </section>

            <!-- Slide: RFE Concept -->
            <section>
                <h2>üîÑ Recursive Feature Elimination (RFE)</h2>
                <h3>Lo·∫°i b·ªè ƒë·∫∑c tr∆∞ng ƒë·ªá quy</h3>

                <div class="step-box">
                    <p><strong>B∆∞·ªõc 1:</strong> Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi T·∫§T C·∫¢ ƒë·∫∑c tr∆∞ng</p>
                </div>
                <div class="step-box">
                    <p><strong>B∆∞·ªõc 2:</strong> X·∫øp h·∫°ng c√°c ƒë·∫∑c tr∆∞ng theo t·∫ßm quan tr·ªçng</p>
                    <p class="small-text">(d·ª±a v√†o coefficients ho·∫∑c feature importance)</p>
                </div>
                <div class="step-box">
                    <p><strong>B∆∞·ªõc 3:</strong> Lo·∫°i b·ªè ƒë·∫∑c tr∆∞ng √çT quan tr·ªçng nh·∫•t</p>
                </div>
                <div class="step-box">
                    <p><strong>B∆∞·ªõc 4:</strong> L·∫∑p l·∫°i B∆∞·ªõc 1-3 cho ƒë·∫øn khi ƒë·∫°t s·ªë l∆∞·ª£ng mong mu·ªën</p>
                </div>

                <div class="highlight-box" style="margin-top: 30px;">
                    <p><span class="emoji">üí°</span> <strong>√ù t∆∞·ªüng:</strong> Lo·∫°i b·ªè d·∫ßn c√°c bi·∫øn "y·∫øu nh·∫•t" ƒë·ªÉ gi·ªØ l·∫°i bi·∫øn "m·∫°nh nh·∫•t"</p>
                </div>
            </section>

            <!-- Slide: RFE Code Basic -->
            <section>
                <h2>üíª RFE - Code c∆° b·∫£n</h2>
                <div class="code-container">
                    <pre><code class="python">from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
from sklearn.datasets import fetch_california_housing
import pandas as pd

# Load d·ªØ li·ªáu
data = fetch_california_housing()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target

# Kh·ªüi t·∫°o m√¥ h√¨nh
model = LinearRegression()

# RFE: Ch·ªçn 4 ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t
rfe = RFE(estimator=model, n_features_to_select=4)
rfe.fit(X, y)

# Xem ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn
selected_features = X.columns[rfe.support_]
print("ƒê·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn:", selected_features.tolist())

# Xem ranking (1 = t·ªët nh·∫•t)
ranking = pd.DataFrame({
    'Feature': X.columns,
    'Ranking': rfe.ranking_
}).sort_values('Ranking')
print("\n", ranking)</code></pre>
                </div>
            </section>

            <!-- Slide: RFE Output Example -->
            <section>
                <h2>üìä RFE - K·∫øt qu·∫£ v√≠ d·ª•</h2>
                
                <div class="highlight-box">
                    <h3>ƒê·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn:</h3>
                    <p style="font-size: 1.2em;">['MedInc', 'AveRooms', 'AveOccup', 'Latitude']</p>
                </div>

                <table class="comparison-table" style="margin-top: 30px;">
                    <thead>
                        <tr>
                            <th>Feature</th>
                            <th>Ranking</th>
                            <th>Selected</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr style="background: rgba(66, 185, 131, 0.2);">
                            <td>MedInc</td>
                            <td>1</td>
                            <td>‚úÖ</td>
                        </tr>
                        <tr style="background: rgba(66, 185, 131, 0.2);">
                            <td>AveRooms</td>
                            <td>1</td>
                            <td>‚úÖ</td>
                        </tr>
                        <tr style="background: rgba(66, 185, 131, 0.2);">
                            <td>Latitude</td>
                            <td>1</td>
                            <td>‚úÖ</td>
                        </tr>
                        <tr style="background: rgba(66, 185, 131, 0.2);">
                            <td>AveOccup</td>
                            <td>1</td>
                            <td>‚úÖ</td>
                        </tr>
                        <tr>
                            <td>Longitude</td>
                            <td>2</td>
                            <td>‚ùå</td>
                        </tr>
                        <tr>
                            <td>HouseAge</td>
                            <td>3</td>
                            <td>‚ùå</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!--
